import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import time
from urllib.parse import urlparse
import io
from openpyxl import Workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter

# â–¼â–¼â–¼ è¨­å®šã‚¨ãƒªã‚¢ â–¼â–¼â–¼
DEFAULT_APP_ID = '1052224946268447244' 
REVIEW_RATE = 0.08  
PRICE_UPLIFT = 1.2  

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ¥½å¤©å¸‚å ´ é‹å–¶æ”¯æ´ãƒ„ãƒ¼ãƒ« Suite", page_icon="ğŸ›ï¸", layout="wide")

# --- CSSã‚¹ã‚¿ã‚¤ãƒ« ---
st.markdown("""
<style>
    .main { padding-top: 2rem; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #BF0000; color: white; }
    .stDownloadButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #008000; color: white; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# å…±é€šãƒ»ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤
# ==========================================

def get_item_key_from_url(url):
    try:
        parsed = urlparse(url)
        path_parts = [p for p in parsed.path.split('/') if p]
        if len(path_parts) >= 2: return path_parts[-1]
        return url
    except: return url

# --- ç«¶åˆåˆ†æç”¨ãƒ­ã‚¸ãƒƒã‚¯ ---
def calculate_metrics(item, uplift, rate):
    price = item['itemPrice']
    review_count = item['reviewCount']
    item_name = item['itemName']
    catch_copy = item.get('catchcopy', '')
    
    adj_price = int(price * uplift)
    total_sales_vol = int(review_count / rate)
    total_sales_amt = total_sales_vol * adj_price
    
    full_text = (item_name + catch_copy).replace(" ", "")
    coupon_flg = "-"
    if any(x in full_text for x in ["ã‚¯ãƒ¼ãƒãƒ³", "OFF", "å€¤å¼•", "SALE"]):
        coupon_flg = "æœ‰"
    
    return {
        "å•†å“å": item_name, "ä¾¡æ ¼": price, "ãƒã‚¤ãƒ³ãƒˆå€ç‡": item['pointRate'],
        "ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡": coupon_flg, "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°": review_count,
        "æ¨å®šç´¯ç©è²©å£²æ•°": total_sales_vol, "æ¨å®šç´¯ç©å£²ä¸Š": total_sales_amt,
        "ã‚·ãƒ§ãƒƒãƒ—å": item['shopName'], "ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰": item['shopCode'],
        "å•†å“URL": item['itemUrl'], "ã‚¸ãƒ£ãƒ³ãƒ«ID": item['genreId']
    }

def search_items(query, app_id, limit=10):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    if "http" in query:
        keyword = get_item_key_from_url(query)
        search_type = "URLæ¤œç´¢"
    elif query.isdigit() and len(query) > 7:
        keyword = query
        search_type = "JANæ¤œç´¢"
    else:
        keyword = query
        search_type = "ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"

    params = {"applicationId": app_id, "keyword": keyword, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['æ¤œç´¢æ¡ä»¶'] = query
                metrics['æ¤œç´¢ã‚¿ã‚¤ãƒ—'] = search_type
                results.append(metrics)
        return results
    except: return []

def get_shop_top_items(shop_code, shop_name, app_id, limit=30):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    params = {"applicationId": app_id, "shopCode": shop_code, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['å¯¾è±¡åº—èˆ—'] = shop_name
                results.append(metrics)
        return results
    except: return []

# --- RPPæ”¹å–„ç”¨ãƒ­ã‚¸ãƒƒã‚¯ ---
def get_current_price_for_rpp(item_manage_number, shop_code, app_id):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    # itemCodeã¯é€šå¸¸ shop_code:item_manage_number ã®å½¢å¼
    # å•†å“ç®¡ç†ç•ªå·ã«shop_codeãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèª
    if shop_code in item_manage_number:
        item_code_param = item_manage_number
    else:
        item_code_param = f"{shop_code}:{item_manage_number}"
    
    params = {
        "applicationId": app_id,
        "itemCode": item_code_param,
        "hits": 1
    }
    try:
        res = requests.get(url, params=params, timeout=5)
        data = res.json()
        if 'Items' in data and len(data['Items']) > 0:
            return data['Items'][0]['Item']['itemPrice']
        return None
    except:
        return None

def smart_read_file(uploaded_file):
    """
    æ¥½å¤©RPPãƒ¬ãƒãƒ¼ãƒˆç‰¹æœ‰ã®ã€Œä¸Šéƒ¨ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹CSV/Excelã€ã‚’
    è‡ªå‹•ã§ãƒ˜ãƒƒãƒ€ãƒ¼ä½ç½®ã‚’ç‰¹å®šã—ã¦èª­ã¿è¾¼ã‚€é–¢æ•°
    """
    filename = uploaded_file.name.lower()
    target_keywords = ["å•†å“ç®¡ç†ç•ªå·", "ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã‚«ãƒ©ãƒ ", "å…¥æœ­å˜ä¾¡"] # ãƒ˜ãƒƒãƒ€ãƒ¼ã«å«ã¾ã‚Œã‚‹ã¯ãšã®è¨€è‘‰
    
    # ---------------------------
    # 1. Excelã®å ´åˆ
    # ---------------------------
    if filename.endswith(('.xlsx', '.xls')):
        try:
            uploaded_file.seek(0)
            # æœ€åˆã®30è¡Œã ã‘èª­ã‚“ã§å ´æ‰€ã‚’æ¢ã™
            df_temp = pd.read_excel(uploaded_file, header=None, nrows=30)
            
            header_idx = -1
            for idx, row in df_temp.iterrows():
                row_str = " ".join(row.astype(str).values)
                if any(kw in row_str for kw in target_keywords):
                    header_idx = idx
                    break
            
            uploaded_file.seek(0)
            if header_idx != -1:
                return pd.read_excel(uploaded_file, header=header_idx), None
            else:
                return pd.read_excel(uploaded_file), None # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°æ™®é€šã«èª­ã‚€
        except Exception as e:
            return None, f"Excelèª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}"

    # ---------------------------
    # 2. CSVã®å ´åˆ
    # ---------------------------
    encodings = ['shift_jis', 'cp932', 'utf-8', 'utf-8-sig']
    
    for enc in encodings:
        try:
            uploaded_file.seek(0)
            # æœ€åˆã®4KBç¨‹åº¦ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ†ã‚­ã‚¹ãƒˆè§£æ
            content_snippet = uploaded_file.read(4096).decode(enc, errors='ignore')
            lines = content_snippet.splitlines()
            
            header_idx = -1
            for i, line in enumerate(lines):
                if any(kw in line for kw in target_keywords):
                    header_idx = i
                    break
            
            uploaded_file.seek(0)
            if header_idx != -1:
                # header=i ã§æŒ‡å®šã€‚skip_blank_lines=Falseã«ã—ãªã„ã¨è¡Œæ•°ãŒãšã‚Œã‚‹ã“ã¨ãŒã‚ã‚‹ãŒã€
                # read_csvã®headeræŒ‡å®šã¯ã€Œæœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡Œã€ã§ã¯ãªãã€Œãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œæ•°(0å§‹ã¾ã‚Š)ã€ãªã®ã§
                # ç´ ç›´ã«æŒ‡å®šã™ã‚Œã°å¤§ä½“å‹•ãã€‚å¿µã®ãŸã‚ engine='python' æ¨å¥¨ã€‚
                df = pd.read_csv(uploaded_file, encoding=enc, header=header_idx, engine='python')
                return df, None
            
        except Exception:
            continue
            
    # ã‚¹ãƒãƒ¼ãƒˆæ¤œçŸ¥ã§å¤±æ•—ã—ãŸå ´åˆã®æœ€çµ‚æ‰‹æ®µ: æ™®é€šã«èª­ã‚€
    for enc in encodings:
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding=enc, engine='python')
            if len(df.columns) > 3: return df, None
        except: pass

    return None, "ãƒ˜ãƒƒãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒRPPãƒ¬ãƒãƒ¼ãƒˆã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚"

# --- Excelç”Ÿæˆ ---
def format_worksheet(worksheet):
    left_align = Alignment(horizontal='left', vertical='center')
    fill_color = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    hyperlink_font = Font(color="0000FF", underline="single")
    num_cols = ["ä¾¡æ ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°", "æ¨å®šç´¯ç©è²©å£²æ•°", "æ¨å®šç´¯ç©å£²ä¸Š", "ç¾åœ¨ä¾¡æ ¼", "å®Ÿç¸¾CPC", "æ¨å¥¨CPC"]
    
    for row in worksheet.iter_rows():
        worksheet.row_dimensions[row[0].row].height = 25
        for cell in row:
            cell.alignment = left_align
            if cell.row == 1:
                cell.fill = fill_color
                continue
            
            header_val = worksheet.cell(row=1, column=cell.column).value
            if header_val in num_cols:
                cell.number_format = '#,##0'
            if header_val == "å•†å“URL" and cell.value:
                cell.hyperlink = cell.value
                cell.font = hyperlink_font

    worksheet.freeze_panes = 'A2'
    worksheet.auto_filter.ref = worksheet.dimensions
    
    for col in worksheet.columns:
        column = get_column_letter(col[0].column)
        worksheet.column_dimensions[column].width = 15

def create_excel_bytes(df1, df2):
    output = io.BytesIO()
    if not df1.empty: df1 = df1.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)
    if not df2.empty: df2 = df2.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)

    cols1 = ['æ¤œç´¢ã‚¿ã‚¤ãƒ—', 'æ¤œç´¢æ¡ä»¶', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'ã‚·ãƒ§ãƒƒãƒ—å', 'å•†å“URL']
    cols2 = ['å¯¾è±¡åº—èˆ—', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'å•†å“URL']
    
    # å­˜åœ¨ã—ãªã„ã‚«ãƒ©ãƒ ã‚’é™¤å¤–ã—ã¦reindex
    valid_cols1 = [c for c in cols1 if c in df1.columns]
    valid_cols2 = [c for c in cols2 if c in df2.columns]
    
    df1 = df1.reindex(columns=valid_cols1) if not df1.empty else pd.DataFrame()
    df2 = df2.reindex(columns=valid_cols2) if not df2.empty else pd.DataFrame()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if not df1.empty:
            df1.to_excel(writer, sheet_name='æ¤œç´¢çµæœ', index=False)
            format_worksheet(writer.sheets['æ¤œç´¢çµæœ'])
        if not df2.empty:
            df2.to_excel(writer, sheet_name='åº—èˆ—åˆ†æ', index=False)
            format_worksheet(writer.sheets['åº—èˆ—åˆ†æ'])
    return output.getvalue()

# ==========================================
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# ==========================================
def main():
    st.title("æ¥½å¤©å¸‚å ´ é‹å–¶æ”¯æ´ãƒ„ãƒ¼ãƒ« Suite")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    st.sidebar.header("âš™ï¸ å…±é€šè¨­å®š")
    user_app_id = st.sidebar.text_input("æ¥½å¤©ã‚¢ãƒ—ãƒªID (ä»»æ„)", value="", type="password", help="ç©ºæ¬„ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆIDã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€å¤§é‡æ¤œç´¢æ™‚ã¯ç‹¬è‡ªã®IDæ¨å¥¨ã§ã™ã€‚")
    APP_ID = user_app_id if user_app_id else DEFAULT_APP_ID

    # ã‚¿ãƒ–è¨­å®š
    tab1, tab2 = st.tabs(["ğŸ“Š ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ«", "ğŸ’° RPPåºƒå‘Šæ”¹å–„ãƒ„ãƒ¼ãƒ«"])

    # -----------------------------------
    # Tab 1: ç«¶åˆåˆ†æ
    # -----------------------------------
    with tab1:
        st.subheader("ç«¶åˆãƒ»å¸‚å ´èª¿æŸ»")
        st.markdown("èª¿æŸ»ã—ãŸã„ **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€JANã€URL** ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        input_text = st.text_area("æ¤œç´¢ãƒªã‚¹ãƒˆ", height=150, placeholder="ä¾‹:\nåŒ—æ¬§ èŠ±ç“¶\n4968912801046\nhttps://item.rakuten.co.jp/...", key="comp_input")
        
        if st.button("åˆ†æã‚’é–‹å§‹ã™ã‚‹", key="comp_btn"):
            if not input_text.strip():
                st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            else:
                target_list = [{'query': line.strip()} for line in input_text.split('\n') if line.strip()]
                status_text = st.empty()
                progress_bar = st.progress(0)
                
                try:
                    sheet1_data = []
                    analyzed_shops = set()
                    
                    # Phase 1: Search
                    total = len(target_list)
                    for i, target in enumerate(target_list):
                        q = target['query']
                        status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total}): {q}")
                        items = search_items(q, APP_ID, limit=10)
                        sheet1_data.extend(items)
                        for item in items:
                            if item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'] not in analyzed_shops:
                                analyzed_shops.add(item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'])
                        progress_bar.progress(int((i+1) / total * 40))

                    # Phase 2: Shop Analysis
                    sheet2_data = []
                    total_shops = len(analyzed_shops)
                    status_text.text(f"åº—èˆ—è©³ç´°åˆ†æä¸­... (å…¨{total_shops}åº—èˆ—)")
                    shop_map = {row['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰']: row['ã‚·ãƒ§ãƒƒãƒ—å'] for row in sheet1_data}
                    
                    for i, s_code in enumerate(analyzed_shops):
                        s_name = shop_map.get(s_code, "ä¸æ˜")
                        shop_items = get_shop_top_items(s_code, s_name, APP_ID, limit=30)
                        sheet2_data.extend(shop_items)
                        current_progress = 40 + int((i+1) / max(1, total_shops) * 60)
                        progress_bar.progress(min(100, current_progress))

                    status_text.text("Excelç”Ÿæˆä¸­...")
                    df1 = pd.DataFrame(sheet1_data)
                    df2 = pd.DataFrame(sheet2_data)
                    excel_data = create_excel_bytes(df1, df2)
                    
                    progress_bar.progress(100)
                    status_text.success("åˆ†æå®Œäº†ï¼")
                    
                    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                    st.download_button(
                        label="ğŸ“Š åˆ†æçµæœExcelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=excel_data,
                        file_name=f"rakuten_analysis_{timestamp}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # -----------------------------------
    # Tab 2: RPPåºƒå‘Šæ”¹å–„
    # -----------------------------------
    with tab2:
        st.subheader("RPPåºƒå‘Š CPCè‡ªå‹•æœ€é©åŒ–")
        st.markdown("""
        **æ‰‹é †:**
        1. RMSã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãŸã€Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ(RPP)ã€ã®CSV(ã¾ãŸã¯Excel)ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€‚
        2. è‡ªåº—èˆ—ã®ã‚·ãƒ§ãƒƒãƒ—ID(URLã®è‹±æ•°å­—)ã‚’å…¥åŠ›ã€‚
        3. å®Ÿè¡Œã™ã‚‹ã¨ã€ç¾åœ¨ã®ä¾¡æ ¼ã‚’å–å¾—ã—ã¦æœ€é©ãªCPCã‚’ææ¡ˆã—ã¾ã™ã€‚
        """)

        col1, col2 = st.columns(2)
        with col1:
            my_shop_code = st.text_input("è‡ªåº—èˆ—ID (URLã®è‹±æ•°å­—)", value="lykke-hygge", help="ä¾¡æ ¼å–å¾—ã®ãŸã‚ã«å¿…è¦ã§ã™ã€‚ä¾‹: lykke-hygge")
        with col2:
            uploaded_file = st.file_uploader("RPPå®Ÿç¸¾ãƒ•ã‚¡ã‚¤ãƒ« (CSV/Excel)", type=['csv', 'xlsx', 'xls'])

        # è¨­å®šã‚¨ãƒªã‚¢
        with st.expander("è©³ç´°è¨­å®š", expanded=True):
            c1, c2, c3 = st.columns(3)
            target_roas = c1.number_input("ç›®æ¨™ROAS (%)", min_value=100, value=400, step=50)
            min_cpc = c2.number_input("æœ€ä½CPC (å††)", min_value=10, value=25)
            max_cpc = c3.number_input("æœ€é«˜CPC (å††)", min_value=10, value=100)

        if st.button("ä¾¡æ ¼å–å¾—ï¼†æ”¹å–„å®Ÿè¡Œ", key="rpp_btn"):
            if not uploaded_file or not my_shop_code:
                st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã¨è‡ªåº—èˆ—IDã¯å¿…é ˆã§ã™ã€‚")
            else:
                try:
                    # ã‚¹ãƒãƒ¼ãƒˆèª­ã¿è¾¼ã¿
                    df_rpp, error_msg = smart_read_file(uploaded_file)
                    
                    if df_rpp is None:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nè©³ç´°: {error_msg}")
                        st.stop()
                    
                    st.write(f"èª­ã¿è¾¼ã¿æˆåŠŸï¼ ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(df_rpp)}ä»¶")
                    progress_rpp = st.progress(0)
                    status_rpp = st.empty()
                    results_rpp = []
                    
                    total_rows = len(df_rpp)
                    
                    for index, row in df_rpp.iterrows():
                        progress_rpp.progress((index + 1) / total_rows)
                        
                        # ã‚«ãƒ©ãƒ åã®ã‚†ã‚‰ãå¯¾å¿œ
                        item_manage_number = row.get('å•†å“ç®¡ç†ç•ªå·', row.get('å•†å“URL', '')).strip()
                        if pd.isna(item_manage_number) or item_manage_number == "":
                            continue # ç©ºè¡Œã‚¹ã‚­ãƒƒãƒ—

                        # ä¾¡æ ¼å–å¾—
                        current_price = get_current_price_for_rpp(item_manage_number, my_shop_code, APP_ID)
                        time.sleep(0.3) # APIè² è·è»½æ¸›
                        
                        # æ•°å€¤å–å¾—ã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
                        try:
                            current_cpc = float(row.get('å®Ÿç¸¾CPC', row.get('å…¥æœ­å˜ä¾¡', 25)))
                            roas = float(row.get('ROAS', 0))
                            clicks = int(row.get('ã‚¯ãƒªãƒƒã‚¯æ•°', 0))
                        except:
                            current_cpc = 25.0
                            roas = 0.0
                            clicks = 0

                        new_cpc = current_cpc
                        reason = "ç¶­æŒ"
                        
                        if roas == 0 and clicks > 20:
                            new_cpc = max(min_cpc, current_cpc - 10)
                            reason = "ã‚¯ãƒªãƒƒã‚¯éå¤šãƒ»å£²ä¸Šãªã—"
                        elif 0 < roas < target_roas:
                            new_cpc = max(min_cpc, current_cpc - 5)
                            reason = "ROASä½ãƒ»æŠ‘åˆ¶"
                        elif roas > (target_roas + 200):
                            new_cpc = min(max_cpc, current_cpc + 10)
                            reason = "ROASå¥½èª¿ãƒ»å¼·åŒ–"
                        
                        results_rpp.append({
                            "å•†å“ç®¡ç†ç•ªå·": item_manage_number,
                            "ç¾åœ¨ä¾¡æ ¼": current_price if current_price else "å–å¾—å¤±æ•—",
                            "å®Ÿç¸¾CPC": int(current_cpc),
                            "æ¨å¥¨CPC": int(new_cpc),
                            "å¤‰æ›´ç†ç”±": reason,
                            "ROAS": roas,
                            "ã‚¯ãƒªãƒƒã‚¯æ•°": clicks
                        })
                    
                    if not results_rpp:
                        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                        st.stop()

                    df_res = pd.DataFrame(results_rpp)
                    st.success("è¨ˆç®—å®Œäº†ï¼")
                    st.dataframe(df_res)
                    
                    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    csv_data = df_res.to_csv(index=False).encode('shift-jis', errors='ignore')
                    st.download_button(
                        label="æ¨å¥¨CPCãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (CSV)",
                        data=csv_data,
                        file_name='rpp_optimized.csv',
                        mime='text/csv'
                    )

                except Exception as e:
                    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()
