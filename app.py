import streamlit as st
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader
from streamlit_authenticator import Hasher
import requests
import pandas as pd
from datetime import datetime
import time
from urllib.parse import urlparse
import io
from openpyxl import Workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter

# â–¼â–¼â–¼ è¨­å®šã‚¨ãƒªã‚¢ â–¼â–¼â–¼
DEFAULT_APP_ID = '1052224946268447244' 
REVIEW_RATE = 0.08  
PRICE_UPLIFT = 1.2  

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro", page_icon="ğŸ“Š", layout="wide")

# --- CSSã‚¹ã‚¿ã‚¤ãƒ« ---
st.markdown("""
<style>
    .main { padding-top: 2rem; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #BF0000; color: white; }
    .stDownloadButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #008000; color: white; }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------
# 1. èªè¨¼ãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†ãƒ­ã‚¸ãƒƒã‚¯
# -------------------------------------------
def load_config():
    with open('config.yaml') as file:
        config = yaml.load(file, Loader=SafeLoader)
    return config

def save_config(config):
    with open('config.yaml', 'w') as file:
        yaml.dump(config, file, default_flow_style=False)

def show_login_page():
    config = load_config()
    
    authenticator = stauth.Authenticate(
        config['credentials'],
        config['cookie']['name'],
        config['cookie']['key'],
        config['cookie']['expiry_days'],
        preauthorized=config['preauthorized']
    )

    # ã‚¿ãƒ–ã§ãƒ­ã‚°ã‚¤ãƒ³ã¨æ–°è¦ç™»éŒ²ã‚’åˆ‡ã‚Šæ›¿ãˆ
    tab1, tab2 = st.tabs(["ğŸ”‘ ãƒ­ã‚°ã‚¤ãƒ³", "ğŸ“ æ–°è¦ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ"])

    # --- ãƒ­ã‚°ã‚¤ãƒ³ã‚¿ãƒ– ---
    with tab1:
        st.subheader("ãƒ­ã‚°ã‚¤ãƒ³")
        name, authentication_status, username = authenticator.login("Login", "main")

        if authentication_status:
            return True, name, username, authenticator
        elif authentication_status is False:
            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™")
            return False, None, None, None
        elif authentication_status is None:
            st.warning("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            return False, None, None, None

    # --- æ–°è¦ç™»éŒ²ã‚¿ãƒ– ---
    with tab2:
        st.subheader("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆä½œæˆ")
        with st.form("register_form"):
            new_email = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
            new_user = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID (åŠè§’è‹±æ•°)", placeholder="ä¾‹: yamada01")
            new_name = st.text_input("æ‹…å½“è€…å")
            new_pass = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
            new_pass2 = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰(ç¢ºèª)", type="password")
            
            # è¿½åŠ é …ç›®
            new_company = st.text_input("ä¼šç¤¾å")
            new_tel = st.text_input("é›»è©±ç•ªå·")
            
            submit = st.form_submit_button("ç™»éŒ²ã™ã‚‹")

            if submit:
                if not (new_email and new_user and new_name and new_pass and new_company and new_tel):
                    st.warning("ã™ã¹ã¦ã®é …ç›®ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                elif new_pass != new_pass2:
                    st.warning("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")
                elif new_user in config['credentials']['usernames']:
                    st.error("ãã®ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¯æ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                else:
                    # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã®ãƒãƒƒã‚·ãƒ¥åŒ–
                    hashed_pass = Hasher([new_pass]).generate()[0]
                    
                    # ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                    config['credentials']['usernames'][new_user] = {
                        'email': new_email,
                        'name': new_name,
                        'password': hashed_pass,
                        'company': new_company,
                        'tel': new_tel
                    }
                    save_config(config)
                    st.success("ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼ã€Œãƒ­ã‚°ã‚¤ãƒ³ã€ã‚¿ãƒ–ã‹ã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„ã€‚")
    
    return False, None, None, None


# -------------------------------------------
# 2. åˆ†æãƒ­ã‚¸ãƒƒã‚¯ (æ—¢å­˜ã‚³ãƒ¼ãƒ‰)
# -------------------------------------------
def get_item_key_from_url(url):
    try:
        parsed = urlparse(url)
        path_parts = [p for p in parsed.path.split('/') if p]
        if len(path_parts) >= 2: return path_parts[-1]
        return url
    except: return url

def calculate_metrics(item, uplift, rate):
    price = item['itemPrice']
    review_count = item['reviewCount']
    item_name = item['itemName']
    catch_copy = item.get('catchcopy', '')
    
    adj_price = int(price * uplift)
    total_sales_vol = int(review_count / rate)
    total_sales_amt = total_sales_vol * adj_price
    
    full_text = (item_name + catch_copy).replace(" ", "")
    coupon_flg = "-"
    if any(x in full_text for x in ["ã‚¯ãƒ¼ãƒãƒ³", "OFF", "å€¤å¼•", "SALE"]):
        coupon_flg = "æœ‰"
    
    return {
        "å•†å“å": item_name, "ä¾¡æ ¼": price, "ãƒã‚¤ãƒ³ãƒˆå€ç‡": item['pointRate'],
        "ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡": coupon_flg, "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°": review_count,
        "æ¨å®šç´¯ç©è²©å£²æ•°": total_sales_vol, "æ¨å®šç´¯ç©å£²ä¸Š": total_sales_amt,
        "ã‚·ãƒ§ãƒƒãƒ—å": item['shopName'], "ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰": item['shopCode'],
        "å•†å“URL": item['itemUrl'], "ã‚¸ãƒ£ãƒ³ãƒ«ID": item['genreId']
    }

def search_items(query, limit=10):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    if "http" in query:
        keyword = get_item_key_from_url(query)
        search_type = "URLæ¤œç´¢"
    elif query.isdigit() and len(query) > 7:
        keyword = query
        search_type = "JANæ¤œç´¢"
    else:
        keyword = query
        search_type = "ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"

    params = {"applicationId": DEFAULT_APP_ID, "keyword": keyword, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['æ¤œç´¢æ¡ä»¶'] = query
                metrics['æ¤œç´¢ã‚¿ã‚¤ãƒ—'] = search_type
                results.append(metrics)
        return results
    except: return []

def get_shop_top_items(shop_code, shop_name, limit=30):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    params = {"applicationId": DEFAULT_APP_ID, "shopCode": shop_code, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['å¯¾è±¡åº—èˆ—'] = shop_name
                results.append(metrics)
        return results
    except: return []

def format_worksheet(worksheet):
    left_align = Alignment(horizontal='left', vertical='center')
    fill_color = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    hyperlink_font = Font(color="0000FF", underline="single")
    num_cols = ["ä¾¡æ ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°", "æ¨å®šç´¯ç©è²©å£²æ•°", "æ¨å®šç´¯ç©å£²ä¸Š"]
    
    for row in worksheet.iter_rows():
        worksheet.row_dimensions[row[0].row].height = 25
        for cell in row:
            cell.alignment = left_align
            if cell.row == 1:
                cell.fill = fill_color
                continue
            
            header_val = worksheet.cell(row=1, column=cell.column).value
            if header_val in num_cols:
                cell.number_format = '#,##0'
            if header_val == "å•†å“URL" and cell.value:
                cell.hyperlink = cell.value
                cell.font = hyperlink_font

    worksheet.freeze_panes = 'A2'
    worksheet.auto_filter.ref = worksheet.dimensions
    
    for col in worksheet.columns:
        column = get_column_letter(col[0].column)
        header_val = col[0].value
        if header_val in ["å•†å“å", "å•†å“URL"]: worksheet.column_dimensions[column].width = 50
        elif header_val in ["æ¤œç´¢æ¡ä»¶", "ã‚·ãƒ§ãƒƒãƒ—å", "å¯¾è±¡åº—èˆ—"]: worksheet.column_dimensions[column].width = 25
        else: worksheet.column_dimensions[column].width = 15

def create_excel_bytes(df1, df2):
    output = io.BytesIO()
    if not df1.empty: df1 = df1.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)
    if not df2.empty: df2 = df2.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)

    cols1 = ['æ¤œç´¢ã‚¿ã‚¤ãƒ—', 'æ¤œç´¢æ¡ä»¶', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'ã‚·ãƒ§ãƒƒãƒ—å', 'å•†å“URL']
    cols2 = ['å¯¾è±¡åº—èˆ—', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'å•†å“URL']
    
    df1 = df1.reindex(columns=cols1)
    df2 = df2.reindex(columns=cols2) if not df2.empty else pd.DataFrame()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if not df1.empty:
            df1.to_excel(writer, sheet_name='æ¤œç´¢çµæœ(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['æ¤œç´¢çµæœ(å£²ä¸Šé †)'])
        if not df2.empty:
            df2.to_excel(writer, sheet_name='åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)'])
    return output.getvalue()


# -------------------------------------------
# 3. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
# -------------------------------------------
def main():
    # èªè¨¼ãƒã‚§ãƒƒã‚¯
    is_logged_in, name, username, authenticator = show_login_page()

    if not is_logged_in:
        st.stop() # ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’æ­¢ã‚ã‚‹

    # â–¼â–¼â–¼ ä»¥ä¸‹ã€ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸå¾Œã«è¡¨ç¤ºã•ã‚Œã‚‹ç”»é¢ â–¼â–¼â–¼
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã¨ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
    with st.sidebar:
        st.write(f"ã‚ˆã†ã“ãã€**{name}** æ§˜")
        config = load_config()
        user_info = config['credentials']['usernames'][username]
        st.info(f"ä¼šç¤¾å: {user_info.get('company', '-')}\n\nTEL: {user_info.get('tel', '-')}")
        authenticator.logout("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ", "sidebar")

    st.title("æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro")
    st.markdown(f"èª¿æŸ»ã—ãŸã„ **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€JANã€URL** ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    input_text = st.text_area("æ¤œç´¢ãƒªã‚¹ãƒˆ", height=150, placeholder="ä¾‹:\n4968912801046\nãƒ€ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ«ãƒ•ã‚¡ãƒ³\nhttps://item.rakuten.co.jp/...")
    
    if st.button("åˆ†æã‚’é–‹å§‹ã™ã‚‹"):
        if not input_text.strip():
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        target_list = [{'query': line.strip()} for line in input_text.split('\n') if line.strip()]
        
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            sheet1_data = []
            sheet2_data = []
            analyzed_shops = set()
            
            # Phase 1
            total = len(target_list)
            for i, target in enumerate(target_list):
                q = target['query']
                status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total}): {q}")
                items = search_items(q, limit=10)
                sheet1_data.extend(items)
                
                for item in items:
                    if item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'] not in analyzed_shops:
                        analyzed_shops.add(item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'])
                
                progress_bar.progress(int((i+1) / total * 40))

            # Phase 2
            total_shops = len(analyzed_shops)
            status_text.text(f"åº—èˆ—è©³ç´°åˆ†æä¸­... (å…¨{total_shops}åº—èˆ—)")
            
            shop_map = {row['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰']: row['ã‚·ãƒ§ãƒƒãƒ—å'] for row in sheet1_data}
            
            for i, s_code in enumerate(analyzed_shops):
                s_name = shop_map.get(s_code, "ä¸æ˜")
                shop_items = get_shop_top_items(s_code, s_name, limit=30)
                sheet2_data.extend(shop_items)
                
                current_progress = 40 + int((i+1) / max(1, total_shops) * 60)
                progress_bar.progress(min(100, current_progress))

            status_text.text("Excelãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
            
            if sheet1_data:
                df1 = pd.DataFrame(sheet1_data)
                df2 = pd.DataFrame(sheet2_data)
                excel_data = create_excel_bytes(df1, df2)
                
                progress_bar.progress(100)
                status_text.success("åˆ†æå®Œäº†ï¼")
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                st.download_button(
                    label="ğŸ“Š Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=excel_data,
                    file_name=f"rakuten_analysis_{timestamp}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
