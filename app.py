import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import time
from urllib.parse import urlparse
import io
from openpyxl import Workbook
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter

# â–¼â–¼â–¼ è¨­å®šã‚¨ãƒªã‚¢ â–¼â–¼â–¼
DEFAULT_APP_ID = '1052224946268447244' 
REVIEW_RATE = 0.08  
PRICE_UPLIFT = 1.2  

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro", page_icon="ğŸ“Š", layout="wide")

# --- CSSã‚¹ã‚¿ã‚¤ãƒ« ---
st.markdown("""
<style>
    .main { padding-top: 2rem; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #BF0000; color: white; }
    .stDownloadButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #008000; color: white; }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------
# ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤
# -------------------------------------------
def get_item_key_from_url(url):
    try:
        parsed = urlparse(url)
        path_parts = [p for p in parsed.path.split('/') if p]
        if len(path_parts) >= 2: return path_parts[-1]
        return url
    except: return url

def calculate_metrics(item, uplift, rate):
    price = item['itemPrice']
    review_count = item['reviewCount']
    item_name = item['itemName']
    catch_copy = item.get('catchcopy', '')
    
    adj_price = int(price * uplift)
    total_sales_vol = int(review_count / rate)
    total_sales_amt = total_sales_vol * adj_price
    
    full_text = (item_name + catch_copy).replace(" ", "")
    coupon_flg = "-"
    if any(x in full_text for x in ["ã‚¯ãƒ¼ãƒãƒ³", "OFF", "å€¤å¼•", "SALE"]):
        coupon_flg = "æœ‰"
    
    return {
        "å•†å“å": item_name, "ä¾¡æ ¼": price, "ãƒã‚¤ãƒ³ãƒˆå€ç‡": item['pointRate'],
        "ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡": coupon_flg, "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°": review_count,
        "æ¨å®šç´¯ç©è²©å£²æ•°": total_sales_vol, "æ¨å®šç´¯ç©å£²ä¸Š": total_sales_amt,
        "ã‚·ãƒ§ãƒƒãƒ—å": item['shopName'], "ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰": item['shopCode'],
        "å•†å“URL": item['itemUrl'], "ã‚¸ãƒ£ãƒ³ãƒ«ID": item['genreId']
    }

def search_items(query, limit=10):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    if "http" in query:
        keyword = get_item_key_from_url(query)
        search_type = "URLæ¤œç´¢"
    elif query.isdigit() and len(query) > 7:
        keyword = query
        search_type = "JANæ¤œç´¢"
    else:
        keyword = query
        search_type = "ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"

    params = {"applicationId": DEFAULT_APP_ID, "keyword": keyword, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['æ¤œç´¢æ¡ä»¶'] = query
                metrics['æ¤œç´¢ã‚¿ã‚¤ãƒ—'] = search_type
                results.append(metrics)
        return results
    except: return []

def get_shop_top_items(shop_code, shop_name, limit=30):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    params = {"applicationId": DEFAULT_APP_ID, "shopCode": shop_code, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['å¯¾è±¡åº—èˆ—'] = shop_name
                results.append(metrics)
        return results
    except: return []

def format_worksheet(worksheet):
    # ã‚¹ã‚¿ã‚¤ãƒ«å®šç¾©
    left_align = Alignment(horizontal='left', vertical='center')
    fill_color = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid") # è–„ã„ã‚°ãƒ¬ãƒ¼
    hyperlink_font = Font(color="0000FF", underline="single") # é’è‰²ãƒªãƒ³ã‚¯
    
    # æ¡åŒºåˆ‡ã‚Šã«ã™ã‚‹ã‚«ãƒ©ãƒ 
    num_cols = ["ä¾¡æ ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°", "æ¨å®šç´¯ç©è²©å£²æ•°", "æ¨å®šç´¯ç©å£²ä¸Š"]
    
    # å…¨ã‚»ãƒ«ãƒ«ãƒ¼ãƒ—è¨­å®š
    for row in worksheet.iter_rows():
        # è¡Œã®é«˜ã•ã‚’25ã«
        worksheet.row_dimensions[row[0].row].height = 25
        
        for cell in row:
            cell.alignment = left_align # å·¦æƒãˆ
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®è¨­å®š
            if cell.row == 1:
                cell.fill = fill_color
                continue
            
            # ãƒ‡ãƒ¼ã‚¿è¡Œã®è¨­å®š
            header_val = worksheet.cell(row=1, column=cell.column).value
            
            # æ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (æ¡åŒºåˆ‡ã‚Š)
            if header_val in num_cols:
                cell.number_format = '#,##0'
            
            # URLãƒã‚¤ãƒ‘ãƒ¼ãƒªãƒ³ã‚¯åŒ–
            if header_val == "å•†å“URL" and cell.value:
                cell.hyperlink = cell.value
                cell.font = hyperlink_font

    # ãƒ˜ãƒƒãƒ€ãƒ¼å›ºå®š
    worksheet.freeze_panes = 'A2'
    # ã‚ªãƒ¼ãƒˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    worksheet.auto_filter.ref = worksheet.dimensions
    
    # åˆ—å¹…èª¿æ•´
    for col in worksheet.columns:
        column = get_column_letter(col[0].column)
        header_val = col[0].value
        if header_val in ["å•†å“å", "å•†å“URL"]: worksheet.column_dimensions[column].width = 50
        elif header_val in ["æ¤œç´¢æ¡ä»¶", "ã‚·ãƒ§ãƒƒãƒ—å", "å¯¾è±¡åº—èˆ—"]: worksheet.column_dimensions[column].width = 25
        else: worksheet.column_dimensions[column].width = 15

def create_excel_bytes(df1, df2):
    output = io.BytesIO()
    
    # å£²ä¸Šé †ã‚½ãƒ¼ãƒˆ
    if not df1.empty: df1 = df1.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)
    if not df2.empty: df2 = df2.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)

    # ã‚«ãƒ©ãƒ ä¸¦ã³æ›¿ãˆ
    cols1 = ['æ¤œç´¢ã‚¿ã‚¤ãƒ—', 'æ¤œç´¢æ¡ä»¶', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'ã‚·ãƒ§ãƒƒãƒ—å', 'å•†å“URL']
    cols2 = ['å¯¾è±¡åº—èˆ—', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'å•†å“URL']
    
    df1 = df1.reindex(columns=cols1)
    df2 = df2.reindex(columns=cols2) if not df2.empty else pd.DataFrame()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        if not df1.empty:
            df1.to_excel(writer, sheet_name='æ¤œç´¢çµæœ(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['æ¤œç´¢çµæœ(å£²ä¸Šé †)'])
        if not df2.empty:
            df2.to_excel(writer, sheet_name='åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)'])
            
    return output.getvalue()

# -------------------------------------------
# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# -------------------------------------------
def main():
    st.title("æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro")
    st.markdown("èª¿æŸ»ã—ãŸã„ **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€JANã€URL** ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆæ”¹è¡Œã§è¤‡æ•°å…¥åŠ›å¯ï¼‰")

    input_text = st.text_area("æ¤œç´¢ãƒªã‚¹ãƒˆ", height=150, placeholder="ä¾‹:\n4968912801046\nãƒ€ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ«ãƒ•ã‚¡ãƒ³\nhttps://item.rakuten.co.jp/...")
    
    if st.button("åˆ†æã‚’é–‹å§‹ã™ã‚‹"):
        if not input_text.strip():
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        target_list = [{'query': line.strip()} for line in input_text.split('\n') if line.strip()]
        
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            sheet1_data = []
            sheet2_data = []
            analyzed_shops = set()
            
            # Phase 1
            total = len(target_list)
            for i, target in enumerate(target_list):
                q = target['query']
                status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total}): {q}")
                items = search_items(q, limit=10)
                sheet1_data.extend(items)
                
                for item in items:
                    if item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'] not in analyzed_shops:
                        analyzed_shops.add(item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'])
                
                progress_bar.progress(int((i+1) / total * 40))

            # Phase 2
            total_shops = len(analyzed_shops)
            status_text.text(f"åº—èˆ—è©³ç´°åˆ†æä¸­... (å…¨{total_shops}åº—èˆ—)")
            
            shop_map = {row['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰']: row['ã‚·ãƒ§ãƒƒãƒ—å'] for row in sheet1_data}
            
            for i, s_code in enumerate(analyzed_shops):
                s_name = shop_map.get(s_code, "ä¸æ˜")
                shop_items = get_shop_top_items(s_code, s_name, limit=30)
                sheet2_data.extend(shop_items)
                
                current_progress = 40 + int((i+1) / max(1, total_shops) * 60)
                progress_bar.progress(min(100, current_progress))

            status_text.text("Excelãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
            
            if sheet1_data:
                df1 = pd.DataFrame(sheet1_data)
                df2 = pd.DataFrame(sheet2_data)
                excel_data = create_excel_bytes(df1, df2)
                
                progress_bar.progress(100)
                status_text.success("åˆ†æå®Œäº†ï¼")
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                st.download_button(
                    label="ğŸ“Š Excelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=excel_data,
                    file_name=f"rakuten_analysis_{timestamp}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
