import streamlit as st
import requests
import pandas as pd
from datetime import datetime
import time
from urllib.parse import urlparse
import openpyxl
from openpyxl.styles import Alignment, PatternFill, Font
from openpyxl.utils import get_column_letter
import io
# â–¼â–¼â–¼ ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¿è­· â–¼â–¼â–¼
password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", type="password")
if password != "LkHg0001":  # â†ã“ã“ã«è¨­å®šã—ãŸã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥ã‚Œã‚‹
    st.warning("æ­£ã—ã„ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã™ã‚‹ã¨æ©Ÿèƒ½ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    st.stop()  # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã†å ´åˆã¯ã“ã“ã§å‡¦ç†ã‚’æ­¢ã‚ã‚‹
# â–¼â–¼â–¼ è¨­å®šã‚¨ãƒªã‚¢ â–¼â–¼â–¼
# â€»è²©å£²æ™‚ã¯ã“ã“ã«ã‚ãªãŸã®IDã‚’è¨­å®šã—ã¾ã™
DEFAULT_APP_ID = '1052224946268447244' 
REVIEW_RATE = 0.08  
PRICE_UPLIFT = 1.0  

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro",
    page_icon="ğŸ“Š",
    layout="wide"
)

# --- ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´ (ä½™ç™½ã‚„ãƒ•ã‚©ãƒ³ãƒˆãªã©) ---
st.markdown("""
<style>
    .main { padding-top: 2rem; }
    .stButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #BF0000; color: white; }
    .stDownloadButton>button { width: 100%; border-radius: 5px; height: 3em; background-color: #008000; color: white; }
</style>
""", unsafe_allow_html=True)

# --- ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•°ç¾¤ (å¤‰æ›´ãªã—) ---
def get_item_key_from_url(url):
    try:
        parsed = urlparse(url)
        path_parts = [p for p in parsed.path.split('/') if p]
        if len(path_parts) >= 2: return path_parts[-1]
        return url
    except: return url

def calculate_metrics(item, uplift, rate):
    price = item['itemPrice']
    review_count = item['reviewCount']
    item_name = item['itemName']
    catch_copy = item.get('catchcopy', '')
    
    adj_price = int(price * uplift)
    total_sales_vol = int(review_count / rate)
    total_sales_amt = total_sales_vol * adj_price
    
    full_text = (item_name + catch_copy).replace(" ", "")
    coupon_flg = "-"
    if any(x in full_text for x in ["ã‚¯ãƒ¼ãƒãƒ³", "OFF", "å€¤å¼•", "SALE"]):
        coupon_flg = "æœ‰"
    
    return {
        "å•†å“å": item_name, "ä¾¡æ ¼": price, "ãƒã‚¤ãƒ³ãƒˆå€ç‡": item['pointRate'],
        "ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡": coupon_flg, "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°": review_count,
        "æ¨å®šç´¯ç©è²©å£²æ•°": total_sales_vol, "æ¨å®šç´¯ç©å£²ä¸Š": total_sales_amt,
        "ã‚·ãƒ§ãƒƒãƒ—å": item['shopName'], "ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰": item['shopCode'],
        "å•†å“URL": item['itemUrl'], "ã‚¸ãƒ£ãƒ³ãƒ«ID": item['genreId']
    }

def search_items(query, limit=10):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    if "http" in query:
        keyword = get_item_key_from_url(query)
        search_type = "URLæ¤œç´¢"
    elif query.isdigit() and len(query) > 7:
        keyword = query
        search_type = "JANæ¤œç´¢"
    else:
        keyword = query
        search_type = "ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢"

    params = {"applicationId": DEFAULT_APP_ID, "keyword": keyword, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['æ¤œç´¢æ¡ä»¶'] = query
                metrics['æ¤œç´¢ã‚¿ã‚¤ãƒ—'] = search_type
                results.append(metrics)
        return results
    except: return []

def get_shop_top_items(shop_code, shop_name, limit=30):
    url = "https://app.rakuten.co.jp/services/api/IchibaItem/Search/20170706"
    params = {"applicationId": DEFAULT_APP_ID, "shopCode": shop_code, "hits": limit, "sort": "-reviewCount", "availability": 1}
    try:
        time.sleep(0.5)
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        results = []
        if 'Items' in data:
            for w in data['Items']:
                metrics = calculate_metrics(w['Item'], PRICE_UPLIFT, REVIEW_RATE)
                metrics['å¯¾è±¡åº—èˆ—'] = shop_name
                results.append(metrics)
        return results
    except: return []

def create_excel_bytes(df1, df2):
    output = io.BytesIO()
    
    # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
    if not df1.empty: df1 = df1.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)
    if not df2.empty: df2 = df2.sort_values(by='æ¨å®šç´¯ç©å£²ä¸Š', ascending=False)

    cols1 = ['æ¤œç´¢ã‚¿ã‚¤ãƒ—', 'æ¤œç´¢æ¡ä»¶', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'ã‚·ãƒ§ãƒƒãƒ—å', 'å•†å“URL']
    cols2 = ['å¯¾è±¡åº—èˆ—', 'å•†å“å', 'ä¾¡æ ¼', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°', 'æ¨å®šç´¯ç©è²©å£²æ•°', 'æ¨å®šç´¯ç©å£²ä¸Š', 'ãƒã‚¤ãƒ³ãƒˆå€ç‡', 'ã‚¯ãƒ¼ãƒãƒ³æœ‰ç„¡', 'å•†å“URL']
    
    df1 = df1.reindex(columns=cols1)
    df2 = df2.reindex(columns=cols2) if not df2.empty else pd.DataFrame()

    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        # ã‚·ãƒ¼ãƒˆ1æ›¸ãè¾¼ã¿
        if not df1.empty:
            df1.to_excel(writer, sheet_name='æ¤œç´¢çµæœ(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['æ¤œç´¢çµæœ(å£²ä¸Šé †)'])
            
        # ã‚·ãƒ¼ãƒˆ2æ›¸ãè¾¼ã¿
        if not df2.empty:
            df2.to_excel(writer, sheet_name='åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)', index=False)
            format_worksheet(writer.sheets['åº—èˆ—åˆ¥å£²ã‚Œç­‹(å£²ä¸Šé †)'])
            
    return output.getvalue()

def format_worksheet(worksheet):
    left_align = Alignment(horizontal='left', vertical='center')
    fill_color = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    hyperlink_font = Font(color="0000FF", underline="single")
    num_cols = ["ä¾¡æ ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç·æ•°", "æ¨å®šç´¯ç©è²©å£²æ•°", "æ¨å®šç´¯ç©å£²ä¸Š"]
    
    for row in worksheet.iter_rows():
        worksheet.row_dimensions[row[0].row].height = 25
        for cell in row:
            cell.alignment = left_align
            if cell.row == 1:
                cell.fill = fill_color
                continue
            
            header_val = worksheet.cell(row=1, column=cell.column).value
            if header_val in num_cols:
                cell.number_format = '#,##0'
            if header_val == "å•†å“URL" and cell.value:
                cell.hyperlink = cell.value
                cell.font = hyperlink_font

    worksheet.freeze_panes = 'A2'
    worksheet.auto_filter.ref = worksheet.dimensions
    
    for col in worksheet.columns:
        column = get_column_letter(col[0].column)
        header_val = col[0].value
        if header_val in ["å•†å“å", "å•†å“URL"]: worksheet.column_dimensions[column].width = 50
        elif header_val in ["æ¤œç´¢æ¡ä»¶", "ã‚·ãƒ§ãƒƒãƒ—å", "å¯¾è±¡åº—èˆ—"]: worksheet.column_dimensions[column].width = 25
        else: worksheet.column_dimensions[column].width = 15

# --- ãƒ¡ã‚¤ãƒ³UI ---
def main():
    st.title("æ¥½å¤©å¸‚å ´ ç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« Pro")
    st.markdown("èª¿æŸ»ã—ãŸã„ **ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€JANã€URL** ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ï¼ˆæ”¹è¡Œã§è¤‡æ•°å…¥åŠ›å¯ï¼‰")

    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    input_text = st.text_area("æ¤œç´¢ãƒªã‚¹ãƒˆ", height=150, placeholder="ä¾‹:\n4968912801046\nãƒ€ã‚¯ãƒˆãƒ¬ãƒ¼ãƒ«ãƒ•ã‚¡ãƒ³\nhttps://item.rakuten.co.jp/...")
    
    # å®Ÿè¡Œãƒœã‚¿ãƒ³
    if st.button("åˆ†æã‚’é–‹å§‹ã™ã‚‹"):
        if not input_text.strip():
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return

        target_list = [{'query': line.strip()} for line in input_text.split('\n') if line.strip()]
        
        # å‡¦ç†é–‹å§‹
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            sheet1_data = []
            sheet2_data = []
            analyzed_shops = set()
            
            # Phase 1
            total = len(target_list)
            for i, target in enumerate(target_list):
                q = target['query']
                status_text.text(f"æ¤œç´¢ä¸­ ({i+1}/{total}): {q}")
                items = search_items(q, limit=10)
                sheet1_data.extend(items)
                
                for item in items:
                    if item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'] not in analyzed_shops:
                        analyzed_shops.add(item['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰'])
                
                progress_bar.progress(int((i+1) / total * 40))

            # Phase 2
            total_shops = len(analyzed_shops)
            status_text.text(f"åº—èˆ—è©³ç´°åˆ†æä¸­... (å…¨{total_shops}åº—èˆ—)")
            
            shop_map = {row['ã‚·ãƒ§ãƒƒãƒ—ã‚³ãƒ¼ãƒ‰']: row['ã‚·ãƒ§ãƒƒãƒ—å'] for row in sheet1_data}
            
            for i, s_code in enumerate(analyzed_shops):
                s_name = shop_map.get(s_code, "ä¸æ˜")
                shop_items = get_shop_top_items(s_code, s_name, limit=30)
                sheet2_data.extend(shop_items)
                
                # 40%ã‹ã‚‰ã‚¹ã‚¿ãƒ¼ãƒˆã—ã¦æ®‹ã‚Š60%ã‚’é€²ã‚ã‚‹
                current_progress = 40 + int((i+1) / max(1, total_shops) * 60)
                progress_bar.progress(min(100, current_progress))

            status_text.text("Excelãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
            
            # çµæœå‡¦ç†
            if sheet1_data:
                df1 = pd.DataFrame(sheet1_data)
                df2 = pd.DataFrame(sheet2_data)
                
                # Excelãƒã‚¤ãƒŠãƒªä½œæˆ
                excel_data = create_excel_bytes(df1, df2)
                
                progress_bar.progress(100)
                status_text.success("åˆ†æå®Œäº†ï¼ä»¥ä¸‹ã®ãƒœã‚¿ãƒ³ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³è¡¨ç¤º
                timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                st.download_button(
                    label="ğŸ“Š åˆ†æçµæœExcelã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=excel_data,
                    file_name=f"rakuten_analysis_{timestamp}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                with st.expander("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
                    st.dataframe(df1.head(10))

            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
